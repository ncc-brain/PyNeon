{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading a Neon dataset/recording\n",
    "In this tutorial, we will show how to load a single Neon recording downloaded from [Pupil Cloud](https://docs.pupil-labs.com/neon/pupil-cloud/) and give an overview of the data structure.\n",
    "\n",
    "## Reading sample data\n",
    "We will use a sample recording produced by the NCC Lab, called `boardView`. This project (collection of recordings on Pupil Cloud) contains two recordings downloaded with the `Timeseries Data + Scene Video` option and a marker mapper enrichment. It can be downloaded with the `get_sample_data()` function. The function returns a `Pathlib.Path` [(reference)](https://docs.python.org/3/library/pathlib.html#pathlib.Path) instance pointing to the downloaded and unzipped directory. PyNeon accepts both `Path` and `string` objects but internally always uses `Path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyneon import get_sample_data, NeonDataset, NeonRecording\n",
    "\n",
    "# Download sample data (if not existing) and return the path\n",
    "sample_dir = get_sample_data(\"boardView\")\n",
    "print(sample_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `OfficeWalk` data has the following structure:\n",
    "\n",
    "```text\n",
    "boardView\n",
    "├── Timeseries Data + Scene Video\n",
    "│   ├── boardview1-d4fd9a27\n",
    "│   │   ├── info.json\n",
    "│   │   ├── gaze.csv\n",
    "│   │   └── ....\n",
    "│   ├── boardview2-713532d5\n",
    "│   │   ├── info.json\n",
    "│   │   ├── gaze.csv\n",
    "│   │   └── ....\n",
    "|   ├── enrichment_info.txt\n",
    "|   └── sections.csv\n",
    "└── boardView_MARKER-MAPPER_boardMapping_csv\n",
    "```\n",
    "\n",
    "The `Timeseries Data + Scene Video` folder contains what PyNeon refers to as a `NeonDataset`. It consists of two recordings, each with its own `info.json` file and data files. These recordings can be loaded either individually as a `NeonRecording`, or as a collective `NeonDataset`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load a `NeonDataset`, specify the path to the `Timeseries Data + Scene Video` folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = sample_dir / \"Timeseries Data + Scene Video\"\n",
    "dataset = NeonDataset(dataset_dir)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`NeonDataset` provides an index-based access to its recordings. The recordings are stored in the `recordings` attribute, which contains a list of `NeonRecording` instances. You can access individual recordings by index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording = dataset[0]  # Internally accesses the recordings attribute\n",
    "print(type(recording))\n",
    "print(recording.recording_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can directly load a single `NeonRecording` by specifying the recording's folder path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_dir = dataset_dir / \"boardview1-d4fd9a27\"\n",
    "recording = NeonRecording(recording_dir)\n",
    "print(type(recording))\n",
    "print(recording.recording_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and metadata of a NeonRecording\n",
    "You can quickly get an overview of the metadata and contents of a `NeonRecording` by printing the instance. The basic metadata (e.g., recording and wearer ID, recording start time and duration) and the path to available data will be displayed. At this point, the data is simply located from the recording's folder path, but it is not yet loaded into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recording)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the output, this recording includes all data files. This tutorial will focus on non-video data. For processing video, refer to the [Neon video tutorial](video.ipynb).\n",
    "\n",
    "Individual data streams can be accessed as properties of the `NeonRecording` instance. For example, the gaze data can be accessed as `recording.gaze`, and upon accessing, the tabular data is loaded into memory. On the other hand, if you try to access unavailable data, PyNeon will return `None` and a warning message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaze and fixation data are available\n",
    "gaze = recording.gaze\n",
    "print(f\"recording.gaze is {gaze}\")\n",
    "\n",
    "saccades = recording.saccades\n",
    "print(f\"recording.saccades is {saccades}\")\n",
    "\n",
    "video = recording.video\n",
    "print(f\"recording.video is {video}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyNeon reads tabular CSV file into specialized classes (e.g., gaze.csv to `NeonGaze`) which all have a `data` attribute that holds the tabular data as a `pandas.DataFrame` [(reference)](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html). Depending on the nature of the data, such classes could be of `NeonStream` or `NeonEV` super classes. `NeonStream` contains (semi)-continuous data streams, while `NeonEV` (dubbed so to avoid confusion with the `NeonEvent` subclass that holds data from `events.csv`) contains sparse event data.\n",
    "\n",
    "The class inheritance relationship is as follows:\n",
    "\n",
    "```text\n",
    "NeonTabular\n",
    "├── NeonStream\n",
    "│   ├── NeonGaze\n",
    "│   ├── NeonEyeStates\n",
    "│   └── NeonIMU\n",
    "└── NeonEV\n",
    "    ├── NeonBlinks\n",
    "    ├── NeonSaccades\n",
    "    ├── NeonFixations\n",
    "    └── NeonEvents\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data as DataFrames\n",
    "\n",
    "The essence of `NeonTabular` is the `data` attribute—a `pandas.DataFrame`. This is a common data structure in Python for handling tabular data. For example, you can print the first 5 rows of the gaze data by calling `gaze.data.head()`, and inspect the data type of each column by calling `gaze.data.dtypes`. \n",
    "\n",
    "Theoretically, you could re-assign `gaze.data` to `gaze_df`, however the conversion scripts written in the next section only work at the class level and not on the dataframe level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gaze.data.head())\n",
    "print(gaze.data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(saccades.data.head())\n",
    "print(saccades.data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyNeon performs the following preprocessing when reading the CSV files:\n",
    "1. Removes the redundant `section id` and `recording id` columns that are present in the raw CSVs.\n",
    "2. Sets the `timestamp [ns]` (or `start timestamp [ns]` for most event files) column as the DataFrame index.\n",
    "3. Automatically assigns appropriate data types to columns. For instance, `Int64` type is assigned to timestamps, `Int32` to event IDs (blink/fixation/saccade ID), and `float64` to float data (e.g. gaze location, pupil size)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like any other `pandas.DataFrame`, you can access individual rows, columns, or subsets of the data using the standard indexing and slicing methods. For example, `gaze.data.iloc[0]` returns the first row of the gaze data, and `gaze.data['gaze x [px]']` (or `gaze['gaze x [px]']`) returns the gaze x-coordinate column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"First row of gaze data:\\n{gaze.data.iloc[0]}\\n\")\n",
    "print(f\"All gaze x values:\\n{gaze['gaze x [px]']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful attributes and methods for NeonStream and NeonEV\n",
    "On top of analyzing `data` with `pandas.DataFrame` attributes and methods, you may also use attributes and methods of the `NeonStream` and `NeonEV` instances containing the `data` to facilitate Neon-specific data analysis. For example, `NeonStream` class has a `ts` property that allows quick access of all timestamps in the data as a `numpy.ndarray` [(reference)](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html).\n",
    "\n",
    "Useful as they are, UTC timestamps in nanoseconds are usually too large for human comprehension. Often we would want to simply know what is the relative time for each data point since the stream start (which is different from the recording start). In PyNeon, this is referred to as `times` and is in seconds. You can access it as a `numpy.ndarray` by calling the `times` property.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gaze.ts)\n",
    "print(gaze.times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timestamps (UTC, in ns), relative time (relative to the stream start, in s), and index are the three units of time that are most commonly used in PyNeon. For example, you can crop the stream by either timestamp or relative time by calling the `crop()` method. The method takes `start` and `end` of the crop window in either UTC timestamps or relative time, and uses `by` to specify which time unit is used. The method returns a new `NeonStream` instance with the cropped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Gaze data points before cropping: {len(gaze)}\")\n",
    "\n",
    "# Crop the gaze data to 5-10 seconds\n",
    "gaze_crop = gaze.crop(5, 10, by=\"time\")  # Crop by time\n",
    "print(f\"Gaze data points after cropping: {len(gaze_crop)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may also want to restrict one stream to the temporal range of another stream. This can be done by calling the `restrict()` method. The method takes another `NeonStream` instance as an argument and crops the stream to the intersection of the two streams' temporal ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imu_crop = recording.imu.restrict(gaze_crop)\n",
    "saccades_crop = saccades.restrict(gaze_crop)\n",
    "print(\n",
    "    f\"IMU first timestamp: {imu_crop.first_ts} > Gaze first timestamp: {gaze_crop.first_ts}\"\n",
    ")\n",
    "print(\n",
    "    f\"IMU last timestamp: {imu_crop.last_ts} < Gaze last timestamp: {gaze_crop.last_ts}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many other attributes and methods available for `NeonStream` and `NeonEV` classes. For a full list, refer to the [API reference](https://ncc-brain.github.io/PyNeon/reference/stream.html). We will also cover some of them in the following tutorials (e.g., [interpolation and concatenation of streams](interpolate_and_concat.ipynb))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An example plot of cropped data\n",
    "\n",
    "Below we show how to easily plot the gaze and saccade data we cropped just now. Since PyNeon data are stored in `pandas.DataFrame`, you can use any plotting library that supports `pandas.DataFrame` as input. Here we use `seaborn` and `matplotlib` to plot the gaze x, y coordinates and the saccade durations (shaded areas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a figure\n",
    "fig, ax = plt.subplots(figsize=(8, 3))\n",
    "\n",
    "# Visualize the 1st saccade\n",
    "for _, sac in saccades_crop.data.iterrows():\n",
    "    ax.axvspan(sac.name, sac[\"end timestamp [ns]\"], color=\"lightgray\")\n",
    "\n",
    "# Visualize gaze x and y\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    data=gaze_crop.data,\n",
    "    x=gaze_crop.data.index,\n",
    "    y=\"gaze x [px]\",\n",
    "    label=\"Gaze x\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    data=gaze_crop.data,\n",
    "    x=gaze_crop.data.index,\n",
    "    y=\"gaze y [px]\",\n",
    "    label=\"Gaze y\",\n",
    ")\n",
    "ax.set_ylabel(\"Gaze location [px]\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing gaze heatmap\n",
    "Finally, we will show how to plot a heatmap of the gaze/fixation data. Since it requires gaze, fixation, and video data, the input it takes is an instance of `NeonRecording` that contains all necessary data. The method `plot_heatmap()`, by default, plots a gaze heatmap with fixations overlaid as circles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = recording.plot_distribution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a clear centre-bias, as participants tend to look more centrally relative to head position."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyneon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
